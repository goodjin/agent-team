# Agent Team v5.0 - 精简版需求文档

**版本**: 5.0.0
**日期**: 2025-02-07
**状态**: 待开发

---

## 一、核心理念

**系统简化为以任务为核心的 Agent 协作系统**

### 1.1 核心思路

```
用户提交任务
    ↓
主 Agent (任务协调者)
    ├─ 接收并分析任务
    ├─ 创建子 Agent 执行具体工作
    ├─ 监控执行进度
    └─ 汇总结果并返回
```

### 1.2 关键原则

1. **以任务为维度** - 不是以项目为维度
2. **一任务一主 Agent** - 每个任务由一个主 Agent 负责
3. **主 Agent 可创建子 Agent** - 按需创建，灵活协作
4. **先做好单 Agent 能力** - 再考虑多 Agent 协作

---

## 二、功能需求

### 2.1 核心功能（P0 - 必须实现）

#### 2.1.1 LLM 循环调用处理

**功能描述**：
- Agent 与 LLM 的迭代对话循环
- 工具调用验证和执行
- 循环终止条件判断

**核心能力**：
1. ✅ 工具调用验证（参数校验、工具存在性检查）
2. ✅ 工具调用重试（网络错误、临时故障自动重试）
3. ✅ 循环检测（避免相同工具调用重复）
4. ✅ 超时控制（单次调用超时、总执行时间限制）
5. ✅ 最大迭代次数限制（防止无限循环）

**技术要求**：
- 最大迭代次数: 10次
- 单次 LLM 调用超时: 60秒
- 总执行超时: 10分钟
- 工具调用失败最多重试: 3次

#### 2.1.2 Token 管理和限制

**功能描述**：
- 单任务 Token 预算管理
- Token 使用统计和告警
- 预算耗尽时的降级策略

**核心能力**：
1. ✅ 单任务预算限制（默认 50,000 tokens）
2. ✅ 实时 Token 使用统计
3. ✅ 预算告警（80%、90% 告警）
4. ✅ 预算耗尽降级（自动压缩上下文或停止执行）

**技术要求**：
- 默认任务预算: 50,000 tokens
- 告警阈值: 80% (40,000 tokens)、90% (45,000 tokens)
- 降级策略: 压缩上下文 → 停止执行

#### 2.1.3 自动会话压缩

**功能描述**：
- 自动压缩对话历史
- 保留关键信息
- 避免超出上下文窗口

**核心能力**：
1. ✅ 滑动窗口策略（保留最近 N 条消息）
2. ✅ 智能总结策略（总结早期对话）
3. ✅ 关键信息保留（系统提示词、任务目标、工具定义）

**技术要求**：
- 保留最近消息数: 10条
- 触发压缩阈值: 上下文达到 80% 窗口大小
- 压缩后保留: 系统提示词 + 总结 + 最近10条

#### 2.1.4 提示词管理

**功能描述**：
- Markdown 格式的提示词配置
- 支持变量替换
- Web 界面编辑和预览

**核心能力**：
1. ✅ Markdown 文件存储提示词
2. ✅ 支持 Handlebars 模板语法
3. ✅ 变量替换（任务信息、工具列表、约束条件）
4. ✅ 提示词热加载（修改后自动生效）
5. ✅ Web 编辑界面（Monaco Editor）
6. ✅ 实时预览功能

**目录结构**：
```
prompts/
├── system/           # 系统级提示词
│   ├── base.md
│   └── tools.md
├── roles/            # 角色提示词
│   ├── master-agent.md
│   ├── developer.md
│   └── tester.md
└── tasks/            # 任务类型提示词
    ├── code-generation.md
    └── bug-fix.md
```

#### 2.1.5 工具链完善

**功能描述**：
- 完善的工具执行框架
- 参数验证和错误处理
- 工具调用重试机制

**核心能力**：
1. ✅ Schema 验证（Zod 验证参数）
2. ✅ 权限检查（危险操作需确认）
3. ✅ 自动重试（临时故障重试，指数退避）
4. ✅ 结果处理（脱敏、截断、格式化）
5. ✅ 执行日志（记录所有工具调用）

**技术要求**：
- 最多重试次数: 3次
- 重试延迟: 1秒 → 2秒 → 4秒（指数退避）
- 结果最大长度: 10,000 字符
- 危险操作: 需用户确认

#### 2.1.6 并发控制

**功能描述**：
- 子 Agent 并发创建和执行
- 工具调用并发限制
- LLM 请求速率控制

**核心能力**：
1. ✅ 子 Agent 并发限制（最多 N 个同时运行）
2. ✅ 工具调用并发限制（最多 M 个同时执行）
3. ✅ 队列机制（超出限制时排队等待）

**技术要求**：
- 最大并发子 Agent: 3个
- 最大并发工具调用: 5个
- 队列最大长度: 100

#### 2.1.7 工作空间机制

**功能描述**：
- 每个任务独立的工作目录
- 子 Agent 独立的子目录
- 工作空间归档和清理

**核心能力**：
1. ✅ 任务工作空间自动创建
2. ✅ 标准目录结构（input、output、temp、logs）
3. ✅ 子 Agent 工作子目录
4. ✅ 工作空间归档（压缩保存）
5. ✅ 自动清理（任务完成后可选清理）

**目录结构**：
```
workspace/
├── task-001/
│   ├── input/          # 输入文件
│   ├── output/         # 输出结果
│   ├── temp/           # 临时文件
│   ├── logs/           # 日志文件
│   └── agents/         # 子 Agent 工作目录
│       ├── agent-001/
│       └── agent-002/
```

### 2.2 Agent 协作功能（P1 - 第二阶段实现）

#### 2.2.1 主 Agent 能力

**功能描述**：
- 任务分析和拆分
- 创建和管理子 Agent
- 结果汇总

**核心能力**：
1. ✅ 任务分析（判断是否需要拆分）
2. ✅ 任务拆分（生成子任务定义）
3. ✅ 子 Agent 创建（按需创建，分配角色）
4. ✅ 执行监控（监听子 Agent 进度）
5. ✅ 结果汇总（整合所有子任务结果）

#### 2.2.2 子 Agent 能力

**功能描述**：
- 独立执行子任务
- 上报进度
- 与主 Agent 通信

**核心能力**：
1. ✅ 任务执行（独立的 LLM 循环）
2. ✅ 进度上报（定期上报执行进度）
3. ✅ 结果返回（完成后返回结果）
4. ✅ 错误处理（失败时上报错误）

#### 2.2.3 Agent 间通信

**功能描述**：
- 事件总线通信
- 消息路由
- 请求-响应模式

**核心能力**：
1. ✅ 事件总线（EventEmitter3）
2. ✅ 广播模式（状态更新）
3. ✅ 点对点通信（请求协助）
4. ✅ 请求-响应模式（超时控制）

### 2.3 用户界面功能（P1 - 第二阶段实现）

#### 2.3.1 任务列表界面

**功能描述**：
- 左侧面板展示所有任务
- 按状态分类显示
- 实时状态更新

**界面布局**：
```
📋 全部任务
✅ 进行中 (3)
  ○ 任务 #001
  ● 任务 #002  ← 当前选中
  ○ 任务 #003
⏸ 暂停 (1)
✔ 已完成 (5)
❌ 失败 (2)

[+ 新建任务]
```

#### 2.3.2 任务详情界面

**功能描述**：
- 显示任务基本信息
- 展示参与的 Agent 列表
- 标记活跃的 Agent
- 显示任务输出

**界面组件**：
1. 任务基本信息（标题、状态、进度、时间）
2. Agent 列表（角色、任务、进度、状态）
3. 输出文件树（目录树展示）
4. 日志查看

#### 2.3.3 Agent 对话界面

**功能描述**：
- 点击 Agent 打开对话窗口
- 查看 Agent 执行历史
- 与 Agent 实时对话
- 调整 Agent 工作内容

**界面功能**：
1. 对话历史（消息、工具调用、结果）
2. 消息输入（发送新指令）
3. 快捷操作（暂停、查看代码、重新生成）
4. Token 使用显示

---

## 三、LLM 服务商支持

### 3.1 支持的服务商

| 服务商 | 官方 SDK | 接入方式 | 优先级 |
|--------|---------|---------|--------|
| OpenAI | ✅ `openai` | 官方 SDK | P0 |
| Anthropic (Claude) | ✅ `@anthropic-ai/sdk` | 官方 SDK | P0 |
| DeepSeek | ⚠️ 兼容 OpenAI | OpenAI SDK | P0 |
| Qwen (通义千问) | ⚠️ 兼容 OpenAI | OpenAI SDK | P1 |
| MiniMax | ⚠️ 兼容 OpenAI/Anthropic | OpenAI SDK | P1 |
| BigModel (智谱 GLM) | ⚠️ 自行实现 | HTTP 调用 | P1 |

### 3.2 配置要求

#### 3.2.1 权重配置

**功能描述**：
- 每个服务商支持权重配置
- 权重用于负载均衡和服务商选择
- 权重为 0 表示不可用

**配置示例**：
```yaml
llm:
  providers:
    openai:
      apiKey: "sk-..."
      weight: 10        # 权重 10
      enabled: true

    claude:
      apiKey: "sk-ant-..."
      weight: 5         # 权重 5
      enabled: true

    deepseek:
      apiKey: ""        # 未配置，不可用
      weight: 0         # 权重 0，不可用
      enabled: false
```

**选择策略**：
1. 过滤掉 `weight: 0` 或 `apiKey` 为空的服务商
2. 过滤掉 `enabled: false` 的服务商
3. 按权重比例随机选择（权重越高，被选中概率越高）
4. 如果服务商失败，尝试下一个（fallback）

#### 3.2.2 角色专属服务商

**功能描述**：
- 不同角色可使用不同的 LLM 服务商
- 支持按角色指定模型

**配置示例**：
```yaml
llm:
  roleMapping:
    master-agent:
      provider: claude
      model: claude-3-5-sonnet-20241022

    developer:
      provider: openai
      model: gpt-4-turbo

    tester:
      provider: deepseek
      model: deepseek-chat
```

---

## 四、非功能需求

### 4.1 性能要求

1. **LLM 响应时间**:
   - 首次响应 < 5秒
   - 流式输出首字符 < 2秒

2. **并发能力**:
   - 支持 3 个子 Agent 同时执行
   - 支持 5 个工具调用同时执行

3. **资源占用**:
   - 内存占用 < 500MB（空闲时）
   - 内存占用 < 2GB（执行时）

### 4.2 可靠性要求

1. **错误处理**:
   - 所有 API 调用必须有错误处理
   - 临时性错误自动重试
   - 永久性错误友好提示

2. **数据持久化**:
   - 任务状态自动保存
   - 系统崩溃后可恢复
   - 关键操作有日志记录

3. **资源清理**:
   - Agent 执行完成后清理资源
   - 临时文件定期清理
   - 内存定期释放

### 4.3 可维护性要求

1. **代码质量**:
   - TypeScript 严格模式
   - 类型覆盖率 > 90%
   - 代码注释覆盖率 > 50%

2. **日志规范**:
   - 结构化日志（JSON 格式）
   - 日志级别清晰（DEBUG、INFO、WARN、ERROR）
   - 关键操作必须记录

3. **测试覆盖**:
   - 单元测试覆盖率 > 70%
   - 核心模块必须有集成测试

---

## 五、开发优先级

### Phase 1: Agent 核心能力（Week 1-2）

**必须完成**：
1. ✅ LLM 循环调用处理
2. ✅ Token 管理和限制
3. ✅ 自动会话压缩
4. ✅ 工具链完善（验证、重试）
5. ✅ 并发控制
6. ✅ 工作空间机制

**验收标准**：
- 单个 Agent 可以稳定执行任务
- Token 预算限制生效
- 会话自动压缩
- 工具调用重试正确
- 并发限制生效

### Phase 2: Agent 协作（Week 3）

**必须完成**：
1. ✅ 主 Agent 实现
2. ✅ 子 Agent 实现
3. ✅ Agent 间通信
4. ✅ 结果汇总

**验收标准**：
- 主 Agent 可以创建子 Agent
- 子 Agent 可以执行任务
- Agent 间可以通信
- 结果正确汇总

### Phase 3: 用户界面（Week 4）

**必须完成**：
1. ✅ 任务列表界面
2. ✅ 任务详情界面
3. ✅ Agent 对话界面
4. ✅ 提示词编辑界面

**验收标准**：
- 界面美观易用
- 实时状态更新
- 可以与 Agent 对话
- 可以编辑提示词

---

## 六、暂不实现的功能

以下功能在 v5.0 中 **不实现**，等核心功能稳定后再考虑：

1. ❌ 复杂的项目管理（只管理任务）
2. ❌ WorkflowEngine（用 Agent 协作替代）
3. ❌ TaskOrchestrator（用 MasterAgent 替代）
4. ❌ AutoScheduler（手动触发任务）
5. ❌ 复杂的定时任务
6. ❌ 熔断、降级、限流等高级特性
7. ❌ 链路追踪
8. ❌ 插件系统
9. ❌ 团队协作功能
10. ❌ 任务模板市场

---

## 七、成功标准

### 7.1 功能标准

1. ✅ 用户可以创建任务并执行
2. ✅ Agent 可以自动调用 LLM 完成任务
3. ✅ 主 Agent 可以创建子 Agent 协作
4. ✅ Token 使用受到限制和管理
5. ✅ 所有工具调用都经过验证
6. ✅ 会话历史自动压缩
7. ✅ 用户可以与 Agent 对话调整工作

### 7.2 质量标准

1. ✅ 无内存泄漏
2. ✅ 无资源泄漏（定时器、文件句柄）
3. ✅ 并发控制正常工作
4. ✅ 错误处理完善
5. ✅ 代码类型安全
6. ✅ 日志清晰可读

### 7.3 体验标准

1. ✅ 界面响应流畅
2. ✅ 错误提示友好
3. ✅ 操作简单直观
4. ✅ 文档完整清晰

---

## 八、风险和依赖

### 8.1 技术风险

1. **LLM API 稳定性** - 依赖第三方服务
   - 缓解措施：多服务商支持、自动 fallback

2. **并发控制复杂性** - 可能出现死锁
   - 缓解措施：使用成熟的并发库（p-limit）

3. **Token 计算准确性** - 不同服务商计算方式不同
   - 缓解措施：使用各服务商的 token 计算库

### 8.2 外部依赖

1. **OpenAI SDK** - 官方 SDK
2. **Anthropic SDK** - 官方 SDK
3. **EventEmitter3** - 事件总线
4. **Handlebars** - 模板引擎
5. **Zod** - 参数验证
6. **p-limit** - 并发控制

---

**文档结束**
