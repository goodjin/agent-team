#!/usr/bin/env node
/**
 * Agent Team é…ç½®åˆå§‹åŒ–å·¥å…·
 */

import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';

const CONFIG_DIR = path.join(os.homedir(), '.agent-team');
const CONFIG_FILE = path.join(CONFIG_DIR, 'config.yaml');

async function initConfig() {
  console.log('ðŸš€ Agent Team é…ç½®åˆå§‹åŒ–\n');
  
  // åˆ›å»ºé…ç½®ç›®å½•
  await fs.mkdir(CONFIG_DIR, { recursive: true });
  
  // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨é…ç½®
  try {
    await fs.access(CONFIG_FILE);
    console.log('âš ï¸  é…ç½®æ–‡ä»¶å·²å­˜åœ¨:', CONFIG_FILE);
    const overwrite = await question('æ˜¯å¦è¦†ç›–çŽ°æœ‰é…ç½®? (y/n): ');
    if (overwrite.toLowerCase() !== 'y' && overwrite.toLowerCase() !== 'æ˜¯') {
      console.log('å·²å–æ¶ˆåˆå§‹åŒ–');
      return;
    }
  } catch {
    // æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç»§ç»­
  }
  
  // ç”Ÿæˆé»˜è®¤é…ç½®
  const defaultConfig = `# Agent Team é…ç½®æ–‡ä»¶
# ä½ç½®: ${CONFIG_FILE}
# ç”Ÿæˆæ—¶é—´: ${new Date().toISOString()}

# LLM é…ç½®
llm:
  # é»˜è®¤æä¾›å•†
  defaultProvider: zhipu-primary
  
  # LLM æœåŠ¡å•†é…ç½®
  providers:
    # Anthropic Claude (éœ€è¦ ANTHROPIC_API_KEY çŽ¯å¢ƒå˜é‡)
    anthropic-primary:
      name: Anthropic Claude
      provider: anthropic
      apiKey: \${ANTHROPIC_API_KEY}
      enabled: false
      models:
        claude-3-5-sonnet-20241022:
          model: claude-3-5-sonnet-20241022
          maxTokens: 4000
          temperature: 0.3
          description: Claude 3.5 Sonnetï¼Œæœ€æ–°ç‰ˆæœ¬
        claude-3-opus-20240229:
          model: claude-3-opus-20240229
          maxTokens: 4000
          temperature: 0.3
          description: Claude 3 Opusï¼Œæœ€å¼ºå¤§çš„æ¨¡åž‹
    
    # OpenAI GPT (éœ€è¦ OPENAI_API_KEY çŽ¯å¢ƒå˜é‡)
    openai-primary:
      name: OpenAI GPT-4
      provider: openai
      apiKey: \${OPENAI_API_KEY}
      baseURL: https://api.openai.com/v1
      enabled: false
      models:
        gpt-4-turbo:
          model: gpt-4-turbo-preview
          maxTokens: 4000
          temperature: 0.3
          description: GPT-4 Turbo
        gpt-4:
          model: gpt-4
          maxTokens: 4000
          temperature: 0.3
          description: GPT-4
        gpt-3.5-turbo:
          model: gpt-3.5-turbo
          maxTokens: 4000
          temperature: 0.3
          description: GPT-3.5 Turbo
    
    # æ™ºè°± GLM (éœ€è¦ ZHIPU_API_KEY çŽ¯å¢ƒå˜é‡)
    zhipu-primary:
      name: æ™ºè°± GLM
      provider: openai
      apiKey: \${ZHIPU_API_KEY}
      baseURL: https://open.bigmodel.cn/api/coding/paas/v4
      enabled: true
      models:
        glm-4:
          model: glm-4
          maxTokens: 8192
          temperature: 0.3
          description: GLM-4ï¼Œæœ€æ–°ç‰ˆæœ¬
        glm-4-plus:
          model: glm-4-plus
          maxTokens: 128000
          temperature: 0.3
          description: GLM-4 Plusï¼Œæ›´å¼ºèƒ½åŠ›
        glm-4-air:
          model: glm-4-air
          maxTokens: 128000
          temperature: 0.3
          description: GLM-4 Airï¼Œè½»é‡é«˜æ•ˆ
    
    # é€šä¹‰åƒé—® (éœ€è¦ DASHSCOPE_API_KEY çŽ¯å¢ƒå˜é‡)
    qwen-primary:
      name: é€šä¹‰åƒé—® Qwen
      provider: openai
      apiKey: \${DASHSCOPE_API_KEY}
      baseURL: https://dashscope.aliyuncs.com/compatible-mode/v1
      enabled: false
      models:
        qwen-max:
          model: qwen-max
          maxTokens: 6000
          temperature: 0.3
          description: é€šä¹‰åƒé—®è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡åž‹
        qwen-plus:
          model: qwen-plus
          maxTokens: 6000
          temperature: 0.3
          description: é€šä¹‰åƒé—®å¢žå¼ºç‰ˆ
    
    # DeepSeek (éœ€è¦ DEEPSEEK_API_KEY çŽ¯å¢ƒå˜é‡)
    deepseek-primary:
      name: DeepSeek
      provider: openai
      apiKey: \${DEEPSEEK_API_KEY}
      baseURL: https://api.deepseek.com
      enabled: false
      models:
        deepseek-chat:
          model: deepseek-chat
          maxTokens: 8192
          temperature: 0.3
          description: DeepSeek Chatï¼Œé€šç”¨å¯¹è¯æ¨¡åž‹
        deepseek-coder:
          model: deepseek-coder
          maxTokens: 8192
          temperature: 0.3
          description: DeepSeek Coderï¼Œä»£ç ä¸“ç”¨æ¨¡åž‹

  # è§’è‰²ä¸“å±žæ¨¡åž‹æ˜ å°„
  roleMapping:
    product-manager:
      providerName: zhipu-primary
      modelName: glm-4
    architect:
      providerName: zhipu-primary
      modelName: glm-4-plus
    developer:
      - providerName: zhipu-primary
        modelName: glm-4
      - providerName: anthropic-primary
        modelName: claude-3-5-sonnet-20241022
    tester:
      providerName: zhipu-primary
      modelName: glm-4-air
    doc-writer:
      providerName: zhipu-primary
      modelName: glm-4-air
  
  # æ•…éšœè½¬ç§»é¡ºåº
  fallbackOrder:
    - anthropic-primary
    - openai-primary
    - zhipu-primary
    - qwen-primary
    - deepseek-primary

# é¡¹ç›®é…ç½®
project:
  name: \${PROJECT_NAME:-my-project}
  path: \${PROJECT_PATH:-.}

# Agent é…ç½®
agent:
  maxIterations: 10
  maxHistory: 50
  autoConfirm: false
  showThoughts: false

# å·¥å…·é…ç½®
tools:
  file:
    allowDelete: false
    allowOverwrite: true
  git:
    autoCommit: false
    confirmPush: true
  code:
    enabled: false

# è§„åˆ™é…ç½®
rules:
  enabled:
    - coding-standards
    - security-rules
  disabled:
    - best-practices
    - project-rules

# æ—¥å¿—é…ç½®
logging:
  enabled: true
  level: info
  logDir: ~/.agent-team/logs
  logToFile: true
  logToConsole: true
  maxFileSize: 10485760
  maxFiles: 30
`;

  await fs.writeFile(CONFIG_FILE, defaultConfig, 'utf-8');
  
  console.log('âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º:', CONFIG_FILE);
  console.log('\nðŸ“ ä¸‹ä¸€æ­¥:');
  console.log('   1. ç¼–è¾‘é…ç½®æ–‡ä»¶: open', CONFIG_FILE);
  console.log('   2. è®¾ç½®çŽ¯å¢ƒå˜é‡:');
  console.log('      export ZHIPU_API_KEY=your-api-key');
  console.log('      æˆ–');
  console.log('      export ANTHROPIC_API_KEY=your-api-key');
  console.log('      æˆ–');
  console.log('      export OPENAI_API_KEY=your-api-key');
  console.log('\nðŸ’¡ æç¤º: å¯ä»¥å°†çŽ¯å¢ƒå˜é‡æ·»åŠ åˆ° ~/.zshrc æˆ– ~/.bashrc');
  console.log('\nðŸš€ å¯åŠ¨ Agent Team: npm run server');
}

function question(prompt) {
  return new Promise((resolve) => {
    const readline = require('readline').createInterface({
      input: process.stdin,
      output: process.stdout,
    });
    readline.question(prompt, (answer) => {
      readline.close();
      resolve(answer);
    });
  });
}

initConfig().catch(console.error);
